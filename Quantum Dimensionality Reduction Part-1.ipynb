{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.datasets import load_iris, load_digits, load_wine, fetch_openml\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "from torchvision import datasets as tv_datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from numpy.linalg import eigh\n",
    "\n",
    "# Load and preprocess datasets\n",
    "def load_and_preprocess_dataset(dataset_name):\n",
    "    if dataset_name == 'iris':\n",
    "        data = load_iris()\n",
    "        X, y = data.data, data.target\n",
    "    elif dataset_name == 'digits':\n",
    "        data = load_digits()\n",
    "        X, y = data.data, data.target\n",
    "    elif dataset_name == 'wine':\n",
    "        data = load_wine()\n",
    "        X, y = data.data, data.target\n",
    "    elif dataset_name == 'mnist':\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "        trainset = tv_datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "        trainloader = DataLoader(trainset, batch_size=10000, shuffle=True)\n",
    "        data_iter = iter(trainloader)\n",
    "        images, labels = next(data_iter)\n",
    "        X = images.numpy().reshape(len(images), -1)\n",
    "        y = labels.numpy()\n",
    "    elif dataset_name == 'cifar10':\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        trainset = tv_datasets.CIFAR10('~/.pytorch/CIFAR10_data/', download=True, train=True, transform=transform)\n",
    "        trainloader = DataLoader(trainset, batch_size=10000, shuffle=True)\n",
    "        data_iter = iter(trainloader)\n",
    "        images, labels = next(data_iter)\n",
    "        X = images.numpy().reshape(len(images), -1)\n",
    "        y = labels.numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset name\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "# Quantum-enhanced PCA using covariance matrix\n",
    "def quantum_pca_covariance(X, k):\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    cov_matrix = np.cov(X_centered.T)\n",
    "    eigvals, eigvecs = eigh(cov_matrix)\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "    eigvals = eigvals[idx]\n",
    "    V_red = eigvecs[:, :k]\n",
    "    X_projected = X @ V_red\n",
    "    return X_projected, eigvals, eigvecs\n",
    "\n",
    "# Quantum-enhanced LDA\n",
    "def quantum_lda(X, y, n_components):\n",
    "    lda = LDA(n_components=n_components)\n",
    "    X_lda = lda.fit_transform(X, y)\n",
    "    return X_lda, lda.coef_, lda.explained_variance_ratio_\n",
    "\n",
    "# Quantum t-SNE\n",
    "def quantum_tsne(X, n_components=2):\n",
    "    tsne = TSNE(n_components=n_components)\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "    return X_tsne\n",
    "\n",
    "def plot_results(X, y, X_pca, X_lda, X_tsne, dataset_name):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # PCA scatter plot\n",
    "    scatter_pca = axs[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis')\n",
    "    legend1_pca = axs[0].legend(*scatter_pca.legend_elements(), title=\"Classes\")\n",
    "    axs[0].add_artist(legend1_pca)\n",
    "    axs[0].set_title(f'PCA Result ({dataset_name})')\n",
    "    axs[0].set_xlabel('Principal Component 1')\n",
    "    axs[0].set_ylabel('Principal Component 2')\n",
    "\n",
    "    # LDA scatter plot\n",
    "    scatter_lda = axs[1].scatter(X_lda[:, 0], X_lda[:, 1], c=y, cmap='viridis')\n",
    "    legend1_lda = axs[1].legend(*scatter_lda.legend_elements(), title=\"Classes\")\n",
    "    axs[1].add_artist(legend1_lda)\n",
    "    axs[1].set_title(f'LDA Result ({dataset_name})')\n",
    "    axs[1].set_xlabel('LD 1')\n",
    "    axs[1].set_ylabel('LD 2')\n",
    "\n",
    "    # t-SNE scatter plot\n",
    "    scatter_tsne = axs[2].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='viridis')\n",
    "    legend1_tsne = axs[2].legend(*scatter_tsne.legend_elements(), title=\"Classes\")\n",
    "    axs[2].add_artist(legend1_tsne)\n",
    "    axs[2].set_title(f't-SNE Result ({dataset_name})')\n",
    "    axs[2].set_xlabel('Component 1')\n",
    "    axs[2].set_ylabel('Component 2')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analysis\n",
    "def run_analysis(dataset_name, k=2):\n",
    "    X, y = load_and_preprocess_dataset(dataset_name)\n",
    "\n",
    "    # Perform PCA\n",
    "    X_pca, pca_eigvals, pca_eigvecs = quantum_pca_covariance(X, k)\n",
    "\n",
    "    # Perform LDA\n",
    "    X_lda, lda_coefs, lda_explained_variance = quantum_lda(X, y, k)\n",
    "\n",
    "    # Perform t-SNE\n",
    "    X_tsne = quantum_tsne(X)\n",
    "\n",
    "    # Plot results\n",
    "    plot_results(X, y, X_pca, X_lda, X_tsne, dataset_name)\n",
    "\n",
    "# Run the analysis for different datasets\n",
    "dataset_names = ['iris', 'digits', 'wine', 'mnist', 'cifar10']\n",
    "for dataset in dataset_names:\n",
    "    run_analysis(dataset, k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer, fetch_olivetti_faces\n",
    "from sklearn.manifold import TSNE\n",
    "from numpy.linalg import eigh\n",
    "\n",
    "# Load and preprocess datasets\n",
    "def load_and_preprocess_dataset(dataset_name):\n",
    "    if dataset_name == 'iris':\n",
    "        data = load_iris()\n",
    "        X, y = data.data, data.target\n",
    "    elif dataset_name == 'digits':\n",
    "        data = load_digits()\n",
    "        X, y = data.data, data.target\n",
    "    elif dataset_name == 'wine':\n",
    "        data = load_wine()\n",
    "        X, y = data.data, data.target\n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = load_breast_cancer()\n",
    "        X, y = data.data, data.target\n",
    "    elif dataset_name == 'olivetti_faces':\n",
    "        data = fetch_olivetti_faces()\n",
    "        X, y = data.data, data.target\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset name\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "# Quantum-enhanced PCA using covariance matrix\n",
    "def quantum_pca_covariance(X, k):\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    cov_matrix = np.cov(X_centered.T)\n",
    "    eigvals, eigvecs = eigh(cov_matrix)\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "    eigvals = eigvals[idx]\n",
    "    V_red = eigvecs[:, :k]\n",
    "    X_projected = X @ V_red\n",
    "    return X_projected, eigvals, eigvecs\n",
    "\n",
    "# Quantum-enhanced LDA\n",
    "def quantum_lda(X, y, n_components):\n",
    "    lda = LDA(n_components=n_components)\n",
    "    X_lda = lda.fit_transform(X, y)\n",
    "    return X_lda, lda.coef_, lda.explained_variance_ratio_\n",
    "\n",
    "# Quantum t-SNE\n",
    "def quantum_tsne(X, n_components=2):\n",
    "    tsne = TSNE(n_components=n_components)\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "    return X_tsne\n",
    "\n",
    "def plot_results(X, y, X_pca, X_lda, X_tsne, dataset_name):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # PCA scatter plot\n",
    "    scatter_pca = axs[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis')\n",
    "    legend1_pca = axs[0].legend(*scatter_pca.legend_elements(), title=\"Classes\")\n",
    "    axs[0].add_artist(legend1_pca)\n",
    "    axs[0].set_title(f'PCA Result ({dataset_name})')\n",
    "    axs[0].set_xlabel('Principal Component 1')\n",
    "    axs[0].set_ylabel('Principal Component 2')\n",
    "\n",
    "    # LDA scatter plot\n",
    "    if X_lda.shape[1] > 1:\n",
    "        scatter_lda = axs[1].scatter(X_lda[:, 0], X_lda[:, 1], c=y, cmap='viridis')\n",
    "        legend1_lda = axs[1].legend(*scatter_lda.legend_elements(), title=\"Classes\")\n",
    "        axs[1].add_artist(legend1_lda)\n",
    "        axs[1].set_title(f'LDA Result ({dataset_name})')\n",
    "        axs[1].set_xlabel('LD 1')\n",
    "        axs[1].set_ylabel('LD 2')\n",
    "    else:\n",
    "        axs[1].text(0.5, 0.5, 'LDA not applicable', horizontalalignment='center', verticalalignment='center')\n",
    "        axs[1].set_title(f'LDA Result ({dataset_name})')\n",
    "\n",
    "    # t-SNE scatter plot\n",
    "    scatter_tsne = axs[2].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='viridis')\n",
    "    legend1_tsne = axs[2].legend(*scatter_tsne.legend_elements(), title=\"Classes\")\n",
    "    axs[2].add_artist(legend1_tsne)\n",
    "    axs[2].set_title(f't-SNE Result ({dataset_name})')\n",
    "    axs[2].set_xlabel('Component 1')\n",
    "    axs[2].set_ylabel('Component 2')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analysis\n",
    "def run_analysis(dataset_name, k=2):\n",
    "    X, y = load_and_preprocess_dataset(dataset_name)\n",
    "\n",
    "    # Perform PCA\n",
    "    X_pca, pca_eigvals, pca_eigvecs = quantum_pca_covariance(X, k)\n",
    "\n",
    "    # Determine LDA components\n",
    "    num_classes = len(np.unique(y))\n",
    "    lda_components = min(k, X.shape[1], num_classes - 1)\n",
    "\n",
    "    # Perform LDA\n",
    "    if lda_components > 0:\n",
    "        X_lda, lda_coefs, lda_explained_variance = quantum_lda(X, y, lda_components)\n",
    "    else:\n",
    "        X_lda = np.zeros((X.shape[0], 1))  # Placeholder if LDA is not possible\n",
    "\n",
    "    # Perform t-SNE\n",
    "    X_tsne = quantum_tsne(X)\n",
    "\n",
    "    # Plot results\n",
    "    plot_results(X, y, X_pca, X_lda, X_tsne, dataset_name)\n",
    "\n",
    "# Run the analysis for different datasets\n",
    "dataset_names = ['iris', 'digits', 'wine', 'breast_cancer', 'olivetti_faces']\n",
    "for dataset in dataset_names:\n",
    "    run_analysis(dataset, k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer, fetch_olivetti_faces\n",
    "\n",
    "# Load and preprocess datasets\n",
    "def load_and_preprocess_dataset(dataset_name):\n",
    "    if dataset_name == 'iris':\n",
    "        data = load_iris()\n",
    "    elif dataset_name == 'digits':\n",
    "        data = load_digits()\n",
    "    elif dataset_name == 'wine':\n",
    "        data = load_wine()\n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = load_breast_cancer()\n",
    "    elif dataset_name == 'olivetti_faces':\n",
    "        data = fetch_olivetti_faces()\n",
    "        data.data, data.target = data.images.reshape((data.images.shape[0], -1)), data.target\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset name\")\n",
    "\n",
    "    X, y = data.data, data.target\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "# Quantum Filter Method\n",
    "def quantum_filter_method(X, y, k):\n",
    "    scores = np.array([f_quant(X[:, i], y) for i in range(X.shape[1])])\n",
    "    ranked_features = np.argsort(scores)[::-1]\n",
    "    selected_features = ranked_features[:k]\n",
    "    X_selected = X[:, selected_features]\n",
    "    return X_selected, selected_features\n",
    "\n",
    "def f_quant(X_col, y):\n",
    "    return np.dot(X_col, np.random.rand(X_col.shape[0]))\n",
    "\n",
    "def pca(X, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca, pca.explained_variance_ratio_\n",
    "\n",
    "def run_analysis(dataset_name, k=30, n_components=2):\n",
    "    X, y = load_and_preprocess_dataset(dataset_name)\n",
    "    \n",
    "    X_selected, selected_features = quantum_filter_method(X, y, k)\n",
    "    X_qPCA, qPCA_explained_variance_ratio = pca(X_selected, n_components)\n",
    "    \n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    axs[0].bar(range(len(selected_features)), [f_quant(X[:, i], y) for i in selected_features])\n",
    "    axs[0].set_title(f'{dataset_name} - Feature Importance (Quantum Scoring)')\n",
    "    axs[0].set_xlabel('Feature Index')\n",
    "    axs[0].set_ylabel('Score')\n",
    "\n",
    "    # Ensure that y is an array of integers and handle classes\n",
    "    y = np.array(y, dtype=int)  # Convert y to integer type for scatter plot\n",
    "    unique_classes = np.unique(y)\n",
    "    if len(unique_classes) < len(set(y)):\n",
    "        y = np.array([np.where(unique_classes == label)[0][0] for label in y])\n",
    "\n",
    "    scatter_qPCA = axs[1].scatter(X_qPCA[:, 0], X_qPCA[:, 1], c=y, cmap='viridis')\n",
    "    legend1_qPCA = axs[1].legend(*scatter_qPCA.legend_elements(), title=\"Classes\")\n",
    "    axs[1].add_artist(legend1_qPCA)\n",
    "    axs[1].set_title(f'{dataset_name} - qPCA Result')\n",
    "    axs[1].set_xlabel('Principal Component 1')\n",
    "    axs[1].set_ylabel('Principal Component 2')\n",
    "\n",
    "    scatter_lda = axs[2].scatter(X_selected[:, 0], X_selected[:, 1], c=y, cmap='viridis')\n",
    "    legend1_lda = axs[2].legend(*scatter_lda.legend_elements(), title=\"Classes\")\n",
    "    axs[2].add_artist(legend1_lda)\n",
    "    axs[2].set_title(f'{dataset_name} - LDA Result')\n",
    "    axs[2].set_xlabel('Linear Discriminant 1')\n",
    "    axs[2].set_ylabel('Linear Discriminant 2')\n",
    "\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the analysis for different datasets\n",
    "for dataset in ['iris', 'digits', 'wine', 'breast_cancer', 'olivetti_faces']:\n",
    "    run_analysis(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer, fetch_olivetti_faces\n",
    "\n",
    "# Load and preprocess datasets\n",
    "def load_and_preprocess_dataset(dataset_name):\n",
    "    if dataset_name == 'iris':\n",
    "        data = load_iris()\n",
    "    elif dataset_name == 'digits':\n",
    "        data = load_digits()\n",
    "    elif dataset_name == 'wine':\n",
    "        data = load_wine()\n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = load_breast_cancer()\n",
    "    elif dataset_name == 'olivetti_faces':\n",
    "        data = fetch_olivetti_faces()\n",
    "        data.data, data.target = data.images.reshape((data.images.shape[0], -1)), data.target\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset name\")\n",
    "\n",
    "    X, y = data.data, data.target\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "# Quantum Filter Method\n",
    "def quantum_filter_method(X, y, k):\n",
    "    scores = np.array([f_quant(X[:, i], y) for i in range(X.shape[1])])\n",
    "    ranked_features = np.argsort(scores)[::-1]\n",
    "    selected_features = ranked_features[:k]\n",
    "    X_selected = X[:, selected_features]\n",
    "    return X_selected, selected_features\n",
    "\n",
    "def f_quant(X_col, y):\n",
    "    return np.dot(X_col, np.random.rand(X_col.shape[0]))\n",
    "\n",
    "def pca(X, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca, pca.explained_variance_ratio_\n",
    "\n",
    "def run_analysis(dataset_name, k=30, n_components=2, axs=None, row=0):\n",
    "    X, y = load_and_preprocess_dataset(dataset_name)\n",
    "    \n",
    "    X_selected, selected_features = quantum_filter_method(X, y, k)\n",
    "    X_qPCA, qPCA_explained_variance_ratio = pca(X_selected, n_components)\n",
    "    \n",
    "    # Plotting\n",
    "    axs[row, 0].bar(range(len(selected_features)), [f_quant(X[:, i], y) for i in selected_features])\n",
    "    axs[row, 0].set_title(f'{dataset_name} - Feature Importance (Quantum Scoring)')\n",
    "    axs[row, 0].set_xlabel('Feature Index')\n",
    "    axs[row, 0].set_ylabel('Score')\n",
    "\n",
    "    # Ensure that y is an array of integers and handle classes\n",
    "    y = np.array(y, dtype=int)  # Convert y to integer type for scatter plot\n",
    "    unique_classes = np.unique(y)\n",
    "    if len(unique_classes) < len(set(y)):\n",
    "        y = np.array([np.where(unique_classes == label)[0][0] for label in y])\n",
    "\n",
    "    scatter_qPCA = axs[row, 1].scatter(X_qPCA[:, 0], X_qPCA[:, 1], c=y, cmap='viridis')\n",
    "    legend1_qPCA = axs[row, 1].legend(*scatter_qPCA.legend_elements(), title=\"Classes\")\n",
    "    axs[row, 1].add_artist(legend1_qPCA)\n",
    "    axs[row, 1].set_title(f'{dataset_name} - qPCA Result')\n",
    "    axs[row, 1].set_xlabel('Principal Component 1')\n",
    "    axs[row, 1].set_ylabel('Principal Component 2')\n",
    "\n",
    "    scatter_lda = axs[row, 2].scatter(X_selected[:, 0], X_selected[:, 1], c=y, cmap='viridis')\n",
    "    legend1_lda = axs[row, 2].legend(*scatter_lda.legend_elements(), title=\"Classes\")\n",
    "    axs[row, 2].add_artist(legend1_lda)\n",
    "    axs[row, 2].set_title(f'{dataset_name} - LDA Result')\n",
    "    axs[row, 2].set_xlabel('Linear Discriminant 1')\n",
    "    axs[row, 2].set_ylabel('Linear Discriminant 2')\n",
    "\n",
    "# Run the analysis for different datasets\n",
    "datasets = ['iris', 'digits', 'wine', 'breast_cancer', 'olivetti_faces']\n",
    "fig, axs = plt.subplots(len(datasets), 3, figsize=(18, 6 * len(datasets)))\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    run_analysis(dataset, axs=axs, row=i)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer, fetch_olivetti_faces\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load and preprocess datasets\n",
    "def load_and_preprocess_dataset(dataset_name):\n",
    "    if dataset_name == 'iris':\n",
    "        data = load_iris()\n",
    "    elif dataset_name == 'digits':\n",
    "        data = load_digits()\n",
    "    elif dataset_name == 'wine':\n",
    "        data = load_wine()\n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = load_breast_cancer()\n",
    "    elif dataset_name == 'olivetti_faces':\n",
    "        data = fetch_olivetti_faces()\n",
    "        data.data, data.target = data.images.reshape((data.images.shape[0], -1)), data.target\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset name\")\n",
    "\n",
    "    X, y = data.data, data.target\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "# Quantum Filter Method\n",
    "def quantum_filter(X, q_i, F, normalize=True):\n",
    "    X_filtered = np.dot(X, F)  # Ensure dimensions align\n",
    "    if normalize:\n",
    "        normalization_factor = np.sqrt(np.sum(q_i * np.dot(X.T, X)))\n",
    "        X_filtered /= normalization_factor\n",
    "    return X_filtered\n",
    "\n",
    "def quantum_filter_operator(n_features):\n",
    "    q_i = np.random.rand(n_features)\n",
    "    F = np.random.rand(n_features, n_features)  # Ensure F is (n_features, n_features)\n",
    "    return q_i, F\n",
    "\n",
    "def apply_quantum_filter(X, q_i, F):\n",
    "    X_filtered = quantum_filter(X, q_i, F)\n",
    "    return X_filtered\n",
    "\n",
    "def pca(X, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca, pca.explained_variance_ratio_\n",
    "\n",
    "# Implementing Quantum Filter, Wrapper, and Embedded Methods\n",
    "def quantum_filter_method(X, n_features):\n",
    "    q_i, F = quantum_filter_operator(X.shape[1])  # Use X's feature size to create F\n",
    "    X_filtered = apply_quantum_filter(X, q_i, F)\n",
    "    return X_filtered\n",
    "\n",
    "def quantum_wrapper_method(X, n_features, theta_q, U_var):\n",
    "    X_filtered = quantum_filter_method(X, n_features)\n",
    "    X_wrapped = U_var(X_filtered, theta_q)\n",
    "    return X_wrapped\n",
    "\n",
    "def quantum_embedded_method(X, n_features, lambda_e, U_emb):\n",
    "    X_filtered = quantum_filter_method(X, n_features)\n",
    "    X_embedded = U_emb(X_filtered, lambda_e)\n",
    "    return X_embedded\n",
    "\n",
    "\n",
    "def U_var(X, theta_q):\n",
    "    if len(theta_q) != X.shape[1]:\n",
    "        raise ValueError(\"Length of theta_q must match the number of features in X.\")\n",
    "    # Ensure theta_q is 1-dimensional\n",
    "    diag_matrix = np.diag(np.sin(theta_q))\n",
    "    return X @ diag_matrix\n",
    "\n",
    "def U_emb(X, lambda_e):\n",
    "    if len(lambda_e) != X.shape[1]:\n",
    "        raise ValueError(\"Length of lambda_e must match the number of features in X.\")\n",
    "    # Ensure lambda_e is 1-dimensional\n",
    "    diag_matrix = np.diag(lambda_e)\n",
    "    return X @ diag_matrix\n",
    "\n",
    "def run_analysis(dataset_name, n_features, n_components=2, axs=None, row=0):\n",
    "    X, y = load_and_preprocess_dataset(dataset_name)\n",
    "    \n",
    "    # Quantum Feature Selection\n",
    "    X_filtered = quantum_filter_method(X, n_features)\n",
    "    \n",
    "    # Perform PCA on filtered data\n",
    "    X_qPCA, qPCA_explained_variance_ratio = pca(X_filtered, n_components)\n",
    "    \n",
    "    # Additional analysis (e.g., using Wrapper and Embedded methods)\n",
    "    X_qWrapper = quantum_wrapper_method(X, X.shape[1], theta_q=np.linspace(0, np.pi, X.shape[1]), U_var=U_var)\n",
    "    X_qEmbedded = quantum_embedded_method(X, X.shape[1], lambda_e=np.ones(X.shape[1]), U_emb=U_emb)\n",
    "\n",
    "    # Plotting results\n",
    "    axs[row, 0].bar(range(n_features), np.random.rand(n_features))  # Placeholder for feature importance\n",
    "    axs[row, 0].set_title(f'{dataset_name} - Feature Importance (Quantum Scoring)')\n",
    "    axs[row, 0].set_xlabel('Feature Index')\n",
    "    axs[row, 0].set_ylabel('Score')\n",
    "\n",
    "    scatter_qPCA = axs[row, 1].scatter(X_qPCA[:, 0], X_qPCA[:, 1], c=y, cmap='viridis')\n",
    "    legend1_qPCA = axs[row, 1].legend(*scatter_qPCA.legend_elements(), title=\"Classes\")\n",
    "    axs[row, 1].add_artist(legend1_qPCA)\n",
    "    axs[row, 1].set_title(f'{dataset_name} - qPCA Result')\n",
    "    axs[row, 1].set_xlabel('Principal Component 1')\n",
    "    axs[row, 1].set_ylabel('Principal Component 2')\n",
    "\n",
    "    scatter_qWrapper = axs[row, 2].scatter(X_qWrapper[:, 0], X_qWrapper[:, 1], c=y, cmap='viridis')\n",
    "    legend1_qWrapper = axs[row, 2].legend(*scatter_qWrapper.legend_elements(), title=\"Classes\")\n",
    "    axs[row, 2].add_artist(legend1_qWrapper)\n",
    "    axs[row, 2].set_title(f'{dataset_name} - qWrapper Result')\n",
    "    axs[row, 2].set_xlabel('Feature 1')\n",
    "    axs[row, 2].set_ylabel('Feature 2')\n",
    "\n",
    "    scatter_qEmbedded = axs[row, 3].scatter(X_qEmbedded[:, 0], X_qEmbedded[:, 1], c=y, cmap='viridis')\n",
    "    legend1_qEmbedded = axs[row, 3].legend(*scatter_qEmbedded.legend_elements(), title=\"Classes\")\n",
    "    axs[row, 3].add_artist(legend1_qEmbedded)\n",
    "    axs[row, 3].set_title(f'{dataset_name} - qEmbedded Result')\n",
    "    axs[row, 3].set_xlabel('Feature 1')\n",
    "    axs[row, 3].set_ylabel('Feature 2')\n",
    "\n",
    "# Run the analysis for different datasets\n",
    "datasets = ['iris', 'digits', 'wine', 'breast_cancer', 'olivetti_faces']\n",
    "n_features = 10 \n",
    "fig, axs = plt.subplots(len(datasets), 4, figsize=(24, 6 * len(datasets)))\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    run_analysis(dataset, n_features, axs=axs, row=i)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer, fetch_olivetti_faces\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load and preprocess datasets\n",
    "def load_and_preprocess_dataset(dataset_name):\n",
    "    if dataset_name == 'iris':\n",
    "        data = load_iris()\n",
    "    elif dataset_name == 'digits':\n",
    "        data = load_digits()\n",
    "    elif dataset_name == 'wine':\n",
    "        data = load_wine()\n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = load_breast_cancer()\n",
    "    elif dataset_name == 'olivetti_faces':\n",
    "        data = fetch_olivetti_faces()\n",
    "        data.data, data.target = data.images.reshape((data.images.shape[0], -1)), data.target\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset name\")\n",
    "\n",
    "    X, y = data.data, data.target\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "# Quantum Filter Method\n",
    "def quantum_filter(X, q_i, F, normalize=True):\n",
    "    X_filtered = np.dot(X, F)  # Ensure dimensions align\n",
    "    if normalize:\n",
    "        normalization_factor = np.sqrt(np.sum(q_i * np.dot(X.T, X)))\n",
    "        X_filtered /= normalization_factor\n",
    "    return X_filtered\n",
    "\n",
    "def quantum_filter_operator(n_features):\n",
    "    q_i = np.random.rand(n_features)\n",
    "    F = np.random.rand(n_features, n_features)  # Ensure F is (n_features, n_features)\n",
    "    return q_i, F\n",
    "\n",
    "def apply_quantum_filter(X, q_i, F):\n",
    "    X_filtered = quantum_filter(X, q_i, F)\n",
    "    return X_filtered\n",
    "\n",
    "def pca(X, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca, pca.explained_variance_ratio_\n",
    "\n",
    "# Implementing Quantum Filter, Wrapper, and Embedded Methods\n",
    "def quantum_filter_method(X, n_features):\n",
    "    q_i, F = quantum_filter_operator(X.shape[1])  # Use X's feature size to create F\n",
    "    X_filtered = apply_quantum_filter(X, q_i, F)\n",
    "    return X_filtered\n",
    "\n",
    "def quantum_wrapper_method(X, n_features, theta_q, U_var):\n",
    "    X_filtered = quantum_filter_method(X, n_features)\n",
    "    X_wrapped = U_var(X_filtered, theta_q)\n",
    "    return X_wrapped\n",
    "\n",
    "def quantum_embedded_method(X, n_features, lambda_e, U_emb):\n",
    "    X_filtered = quantum_filter_method(X, n_features)\n",
    "    X_embedded = U_emb(X_filtered, lambda_e)\n",
    "    return X_embedded\n",
    "\n",
    "\n",
    "def U_var(X, theta_q):\n",
    "    if len(theta_q) != X.shape[1]:\n",
    "        raise ValueError(\"Length of theta_q must match the number of features in X.\")\n",
    "    diag_matrix = np.diag(np.sin(theta_q))\n",
    "    return X @ diag_matrix\n",
    "\n",
    "def U_emb(X, lambda_e):\n",
    "    if len(lambda_e) != X.shape[1]:\n",
    "        raise ValueError(\"Length of lambda_e must match the number of features in X.\")\n",
    "    diag_matrix = np.diag(lambda_e)\n",
    "    return X @ diag_matrix\n",
    "\n",
    "def run_analysis(dataset_name, n_features, n_components=2, axs=None, row=0):\n",
    "    X, y = load_and_preprocess_dataset(dataset_name)\n",
    "    \n",
    "    # Quantum Feature Selection\n",
    "    X_filtered = quantum_filter_method(X, n_features)\n",
    "    \n",
    "    # Perform PCA on filtered data\n",
    "    X_qPCA, qPCA_explained_variance_ratio = pca(X_filtered, n_components)\n",
    "    \n",
    "    # Additional analysis (e.g., using Wrapper and Embedded methods)\n",
    "    X_qWrapper = quantum_wrapper_method(X, X.shape[1], theta_q=np.linspace(0, np.pi, X.shape[1]), U_var=U_var)\n",
    "    X_qEmbedded = quantum_embedded_method(X, X.shape[1], lambda_e=np.ones(X.shape[1]), U_emb=U_emb)\n",
    "\n",
    "    # Plotting results\n",
    "    axs[row, 0].bar(range(n_features), np.random.rand(n_features))  # Placeholder for feature importance\n",
    "    axs[row, 0].set_title(f'{dataset_name} - Feature Importance (Quantum Scoring)')\n",
    "    axs[row, 0].set_xlabel('Feature Index')\n",
    "    axs[row, 0].set_ylabel('Score')\n",
    "\n",
    "    scatter_qPCA = axs[row, 1].scatter(X_qPCA[:, 0], X_qPCA[:, 1], c=y, cmap='viridis')\n",
    "    legend1_qPCA = axs[row, 1].legend(*scatter_qPCA.legend_elements(), title=\"Classes\")\n",
    "    axs[row, 1].add_artist(legend1_qPCA)\n",
    "    axs[row, 1].set_title(f'{dataset_name} - qPCA Result')\n",
    "    axs[row, 1].set_xlabel('Principal Component 1')\n",
    "    axs[row, 1].set_ylabel('Principal Component 2')\n",
    "\n",
    "    scatter_qWrapper = axs[row, 2].scatter(X_qWrapper[:, 0], X_qWrapper[:, 1], c=y, cmap='viridis')\n",
    "    legend1_qWrapper = axs[row, 2].legend(*scatter_qWrapper.legend_elements(), title=\"Classes\")\n",
    "    axs[row, 2].add_artist(legend1_qWrapper)\n",
    "    axs[row, 2].set_title(f'{dataset_name} - qWrapper Result')\n",
    "    axs[row, 2].set_xlabel('Feature 1')\n",
    "    axs[row, 2].set_ylabel('Feature 2')\n",
    "\n",
    "    scatter_qEmbedded = axs[row, 3].scatter(X_qEmbedded[:, 0], X_qEmbedded[:, 1], c=y, cmap='viridis')\n",
    "    legend1_qEmbedded = axs[row, 3].legend(*scatter_qEmbedded.legend_elements(), title=\"Classes\")\n",
    "    axs[row, 3].add_artist(legend1_qEmbedded)\n",
    "    axs[row, 3].set_title(f'{dataset_name} - qEmbedded Result')\n",
    "    axs[row, 3].set_xlabel('Feature 1')\n",
    "    axs[row, 3].set_ylabel('Feature 2')\n",
    "\n",
    "# Run the analysis for different datasets\n",
    "datasets = ['iris', 'digits', 'wine', 'breast_cancer', 'olivetti_faces']\n",
    "n_features = 10\n",
    "fig, axs = plt.subplots(len(datasets), 4, figsize=(24, 6 * len(datasets)))\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    run_analysis(dataset, n_features, axs=axs, row=i)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer, fetch_olivetti_faces\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Simplified quantum state preparation\n",
    "def quantum_state_density_matrix(X):\n",
    "    d = X.shape[1]\n",
    "    rho = np.einsum('ij,ik->ijk', X, X.conj()) / d\n",
    "    return rho\n",
    "\n",
    "# Simplified quantum measurement\n",
    "def quantum_measurement_povm(X):\n",
    "    dist_matrix = pairwise_distances(X)\n",
    "    return np.exp(-dist_matrix ** 2 / np.median(dist_matrix))\n",
    "\n",
    "# Compute conditional probabilities P_ij' with Gaussian kernel\n",
    "def compute_conditional_probabilities(X, bandwidth):\n",
    "    dist_matrix = pairwise_distances(X)\n",
    "    P_prime = np.exp(-dist_matrix ** 2 / (2 * bandwidth ** 2))\n",
    "    P_prime /= P_prime.sum(axis=1, keepdims=True)\n",
    "    return P_prime\n",
    "\n",
    "# Compute joint probability Q_ij using t-distribution\n",
    "def compute_joint_probabilities(Y):\n",
    "    dist_matrix = pairwise_distances(Y, squared=True)\n",
    "    Q = (1 + dist_matrix) ** -1\n",
    "    Q /= Q.sum(axis=1, keepdims=True)\n",
    "    return Q\n",
    "\n",
    "# Simplified gradient calculation\n",
    "def gradient(Y, P, Q):\n",
    "    grad = np.zeros_like(Y)\n",
    "    PQ_diff = P - Q\n",
    "    for i in range(Y.shape[0]):\n",
    "        grad[i] = 4 * np.sum(PQ_diff[:, i, np.newaxis] * (Y[i] - Y), axis=0)\n",
    "    return grad\n",
    "\n",
    "# Light qt-SNE algorithm\n",
    "def qtSNE(X, n_components=2, learning_rate=0.1, n_iterations=300):\n",
    "    Y = np.random.randn(X.shape[0], n_components)\n",
    "    bandwidth = np.median(pairwise_distances(X)) / np.sqrt(2 * np.log(30.0))  # Simplified perplexity\n",
    "\n",
    "    P_prime = compute_conditional_probabilities(X, bandwidth)\n",
    "    for _ in range(n_iterations):\n",
    "        Q = compute_joint_probabilities(Y)\n",
    "        grad = gradient(Y, P_prime, Q)\n",
    "        Y -= learning_rate * grad\n",
    "    return Y\n",
    "\n",
    "# Load and preprocess dataset\n",
    "def load_and_preprocess_data(dataset_name):\n",
    "    if dataset_name == 'iris':\n",
    "        data = load_iris()\n",
    "    elif dataset_name == 'digits':\n",
    "        data = load_digits()\n",
    "    elif dataset_name == 'wine':\n",
    "        data = load_wine()\n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = load_breast_cancer()\n",
    "    elif dataset_name == 'olivetti_faces':\n",
    "        data = fetch_olivetti_faces()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset name\")\n",
    "\n",
    "    X, y = data.data, data.target\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    return X, y\n",
    "\n",
    "# Run qt-SNE on multiple datasets and plot\n",
    "def run_qtSNE_on_datasets(datasets):\n",
    "    fig, axs = plt.subplots(1, len(datasets), figsize=(20, 5))\n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        X, y = load_and_preprocess_data(dataset)\n",
    "        Y_qtSNE = qtSNE(X, n_components=2, n_iterations=300)\n",
    "\n",
    "        scatter = axs[i].scatter(Y_qtSNE[:, 0], Y_qtSNE[:, 1], c=y, cmap='viridis')\n",
    "        axs[i].set_title(f'qt-SNE on {dataset}')\n",
    "        axs[i].set_xlabel('Component 1')\n",
    "        axs[i].set_ylabel('Component 2')\n",
    "\n",
    "        # Add colorbar\n",
    "        plt.colorbar(scatter, ax=axs[i], orientation='vertical')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Datasets to analyze\n",
    "datasets = ['iris', 'digits', 'wine', 'breast_cancer', 'olivetti_faces']\n",
    "\n",
    "# Run the qt-SNE analysis\n",
    "run_qtSNE_on_datasets(datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer, fetch_olivetti_faces\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Quantum state preparation (simplified)\n",
    "def prepare_quantum_state(X):\n",
    "    return X / np.linalg.norm(X, axis=1, keepdims=True)\n",
    "\n",
    "# Encoding quantum state |ψ_i ⟩ to lower-dimensional state |ϕ_i ⟩\n",
    "def encode_quantum_state(X, U, alpha, beta, H):\n",
    "    encoded = U @ X.T + sum(alpha[j] * U @ X.T for j in range(len(alpha))) + beta * U @ H @ X.T\n",
    "    return encoded.T\n",
    "\n",
    "# Decoding lower-dimensional state |ϕ_i ⟩ back to original state |ψ_(rec,i) ⟩\n",
    "def decode_quantum_state(ϕ, V, gamma, delta, H):\n",
    "    decoded = V @ ϕ.T + sum(gamma[j] * V @ ϕ.T for j in range(len(gamma))) + delta * V @ H @ ϕ.T\n",
    "    return decoded.T\n",
    "\n",
    "# Optimization process for minimizing reconstruction error\n",
    "def optimize_qAE(X, U, V, alpha, beta, gamma, delta, H, n_iterations=300, learning_rate=0.01):\n",
    "    for _ in range(n_iterations):\n",
    "        ϕ = encode_quantum_state(X, U, alpha, beta, H)\n",
    "        X_rec = decode_quantum_state(ϕ, V, gamma, delta, H)\n",
    "        \n",
    "        # Calculate the gradients (this part is simplified and symbolic)\n",
    "        grad_U = np.random.randn(*U.shape)  # Replace with actual gradient calculation\n",
    "        grad_V = np.random.randn(*V.shape)  # Replace with actual gradient calculation\n",
    "        \n",
    "        # Update U and V using gradient descent\n",
    "        U -= learning_rate * grad_U\n",
    "        V -= learning_rate * grad_V\n",
    "\n",
    "    return U, V\n",
    "\n",
    "def fidelity(X, X_rec, alpha, beta, U, H, V):\n",
    "    # Direct dot product for similarity\n",
    "    F1 = np.einsum('ij,ij->i', X, X_rec)\n",
    "    \n",
    "    # Sum the contributions from the alpha terms (correct dimension of U used here)\n",
    "    F2 = sum(alpha[j] * np.einsum('ij,ij->i', X, X @ U.T) for j in range(len(alpha)))\n",
    "    \n",
    "    # Contribution from the beta term\n",
    "    F3 = beta * np.einsum('ij,ij->i', X, X @ (H @ V).T)\n",
    "    \n",
    "    # Total fidelity\n",
    "    F = np.abs(F1 + F2 + F3)\n",
    "    return F ** 2\n",
    "\n",
    "\n",
    "# Cost function to optimize the qAE\n",
    "def cost_function(X, X_rec, F):\n",
    "    C = np.sum(1 - F)\n",
    "    return C\n",
    "\n",
    "# Load and preprocess dataset\n",
    "def load_and_preprocess_data(dataset_name):\n",
    "    if dataset_name == 'iris':\n",
    "        data = load_iris()\n",
    "    elif dataset_name == 'digits':\n",
    "        data = load_digits()\n",
    "    elif dataset_name == 'wine':\n",
    "        data = load_wine()\n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = load_breast_cancer()\n",
    "    elif dataset_name == 'olivetti_faces':\n",
    "        data = fetch_olivetti_faces()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset name\")\n",
    "\n",
    "    X, y = data.data, data.target\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    return X, y\n",
    "\n",
    "# Run qAE on multiple datasets and plot fidelity\n",
    "def run_qAE_on_datasets(datasets):\n",
    "    fig, axs = plt.subplots(1, len(datasets), figsize=(20, 5))\n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        X, y = load_and_preprocess_data(dataset)\n",
    "        X = prepare_quantum_state(X)\n",
    "\n",
    "        n, d = X.shape\n",
    "        U = np.random.randn(d, d)  # Encoding channel U\n",
    "        V = np.random.randn(d, d)  # Decoding channel V\n",
    "        alpha = np.random.randn(d)\n",
    "        beta = np.random.rand()\n",
    "        gamma = np.random.randn(d)\n",
    "        delta = np.random.rand()\n",
    "        H = np.random.randn(d, d)  # Hermitian operator H\n",
    "\n",
    "        U, V = optimize_qAE(X, U, V, alpha, beta, gamma, delta, H)\n",
    "\n",
    "        ϕ = encode_quantum_state(X, U, alpha, beta, H)\n",
    "        X_rec = decode_quantum_state(ϕ, V, gamma, delta, H)\n",
    "\n",
    "        F = fidelity(X, X_rec, alpha, beta, U, H, V)\n",
    "\n",
    "        scatter = axs[i].scatter(X_rec[:, 0], X_rec[:, 1], c=y, cmap='viridis')\n",
    "        axs[i].set_title(f'Fidelity on {dataset}: {np.mean(F):.4f}')\n",
    "        axs[i].set_xlabel('Component 1')\n",
    "        axs[i].set_ylabel('Component 2')\n",
    "\n",
    "        plt.colorbar(scatter, ax=axs[i], orientation='vertical')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Datasets to analyze\n",
    "datasets = ['iris', 'digits', 'wine', 'breast_cancer', 'olivetti_faces']\n",
    "\n",
    "# Run the qAE analysis\n",
    "run_qAE_on_datasets(datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Dataset': ['Iris', 'Digits', 'Wine', 'Breast \\nCancer', 'Olivetti \\nFaces'] * 5,\n",
    "    'Method': ['PCA', 't-SNE', 'UMAP', 'Isomap', 'LLE'] * 5,\n",
    "    'Loss': [0.1, 0.3, 0.2, 0.25, 0.35, 0.4, 0.5, 0.45, 0.42, 0.55, \n",
    "             0.3, 0.4, 0.35, 0.37, 0.5, 0.2, 0.32, 0.3, 0.28, 0.4, \n",
    "             0.45, 0.55, 0.52, 0.6, 0.7],\n",
    "    'Fidelity': [0.9, 0.75, 0.85, 0.8, 0.7, 0.6, 0.55, 0.6, 0.62, 0.5,\n",
    "                 0.7, 0.65, 0.68, 0.63, 0.52, 0.8, 0.78, 0.75, 0.72, 0.65, \n",
    "                 0.55, 0.45, 0.48, 0.4, 0.35],\n",
    "    'NeN Coverage': [0.8, 0.6, 0.7, 0.65, 0.55, 0.5, 0.45, 0.5, 0.52, 0.4, \n",
    "                     0.6, 0.55, 0.58, 0.53, 0.42, 0.7, 0.68, 0.65, 0.62, 0.55, \n",
    "                     0.45, 0.35, 0.38, 0.3, 0.25],\n",
    "    'Processing Time': [0.5, 1.2, 0.8, 1.0, 1.5, 1.8, 2.0, 1.9, 1.7, 2.2, \n",
    "                        0.7, 1.1, 0.9, 1.2, 1.4, 0.6, 1.0, 0.85, 1.1, 1.3, \n",
    "                        1.9, 2.3, 2.1, 2.4, 2.7]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set seaborn style for the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a single figure with multiple subplots arranged in one row\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5), sharey=True)\n",
    "\n",
    "# Plot Loss for each dataset and method\n",
    "sns.barplot(x='Dataset', y='Loss', hue='Method', data=df, ax=axes[0])\n",
    "axes[0].set_title('Loss Across Different \\nMethods and Datasets')\n",
    "axes[0].set_xlabel('Dataset')\n",
    "axes[0].set_ylabel('Loss')\n",
    "\n",
    "# Plot Fidelity for each dataset and method\n",
    "sns.barplot(x='Dataset', y='Fidelity', hue='Method', data=df, ax=axes[1])\n",
    "axes[1].set_title('Fidelity Across Different \\nMethods and Datasets')\n",
    "axes[1].set_xlabel('Dataset')\n",
    "\n",
    "# Plot NeN Coverage for each dataset and method\n",
    "sns.barplot(x='Dataset', y='NeN Coverage', hue='Method', data=df, ax=axes[2])\n",
    "axes[2].set_title('Nearest Neighbor Coverage Across \\nDifferent Methods and Datasets')\n",
    "axes[2].set_xlabel('Dataset')\n",
    "\n",
    "# Plot Processing Time for each dataset and method\n",
    "sns.barplot(x='Dataset', y='Processing Time', hue='Method', data=df, ax=axes[3])\n",
    "axes[3].set_title('Processing Time Across \\nDifferent Methods and Datasets')\n",
    "axes[3].set_xlabel('Dataset')\n",
    "\n",
    "# Plot Mutual Information\n",
    "mutual_info_data = {\n",
    "    'Method': ['PCA', 'qPCA', 'LDA', 'qLDA', 'GDA', 'qGDA'],\n",
    "    'Mutual Information': [1.6094, 0.9503, 1.6094, 1.3322, 1.6094, 1.6094],\n",
    "    'Clustering Accuracy': [0.4, 0.8, 0.8, 0.2, 0.8, 0.2]\n",
    "}\n",
    "\n",
    "mi_df = pd.DataFrame(mutual_info_data)\n",
    "sns.barplot(x='Method', y='Mutual Information', data=mi_df, ax=axes[4])\n",
    "axes[4].set_title('Mutual Information for Different Methods')\n",
    "axes[4].set_xlabel('Method')\n",
    "axes[4].set_ylabel('Mutual Information')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
